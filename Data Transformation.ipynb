{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you're writing a lot of code - you're doing it wrong\n",
    "\n",
    "\n",
    "### Ryan Kazmerik\n",
    "* Data Scientist, Encana Corporation\n",
    "* Mount Royal University, Bachelor CIS (2011)\n",
    "* Wilfrid Laurier University, Master MAC (2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with our first data representation: Comma seperated values, and use the built in Python library CSV to read the contents of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('articles.csv',  encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        print(\", \".join(row), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV is a great storage format, compact, and readable - but a little clumsy to work with.\n",
    "\n",
    "## Let's convert this CSV into another data structure: List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_list = []\n",
    "\n",
    "with open('articles.csv',  encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        articles_list.append(row)\n",
    "        \n",
    "print(\"Total number of articles:\", len(articles_list)-1)\n",
    "print(\"Total number of columns:\", len(articles_list[0]), end='\\n\\n')\n",
    "\n",
    "print(\"See the 50th article:\")\n",
    "print(articles_list[50])\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Print the first 10 titles:\")\n",
    "print()\n",
    "\n",
    "titles = [a[4] for a in articles_list[2:10]]\n",
    "\n",
    "for t in titles:\n",
    "    print('   ',t, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a list, we can easily get some basic stats on the articles, iterate through the items and build custom ranges.\n",
    "\n",
    "## But if we want to add a new property (ex. Sentiment) lists can be difficult to work with.. so it's best to convert our list items into objects a.k.a JSON\n",
    "\n",
    "## We'll use the built in Python library 'json' for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "NLTK = SIA()\n",
    "\n",
    "import json\n",
    "\n",
    "articles_json = [a for a in csv.DictReader(open('articles.csv', encoding=\"utf8\"))]\n",
    "\n",
    "for article in articles_json:\n",
    "    \n",
    "    sentiment = NLTK.polarity_scores(article['description'])\n",
    "    \n",
    "    article.update({'sentiment': sentiment['compound']})\n",
    "    \n",
    "print(json.dumps(articles_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have a sentiment score for each article, let's produce some aggregations - what if we wanted to see the average sentiment per day?\n",
    "\n",
    "## We'll use a popular library called Pandas for this, and a data representation: Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "df = pd.DataFrame.from_dict(json_normalize(articles_json), orient='columns')\n",
    "\n",
    "df['day'] = df['publishedAt'].str.split('T').str[0]\n",
    "df = df.groupby(['day']).agg({'sentiment':\"mean\",'description': \"count\"})\n",
    "df.columns = [\"avg_sentiment\", \"doc_count\"]\n",
    "\n",
    "print(df)\n",
    "\n",
    "aggs = df.reset_index().to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's compare it with the stock price of one of the top solar energy producing companies in North America : Vivint Solar\n",
    "\n",
    "## We can use the 'request' library to make an API call to a stock feed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=VSLR&apikey=KUTLFACJXW9LIKLO'\n",
    "\n",
    "stocks = json.loads(requests.get(api).text)\n",
    "\n",
    "print(json.dumps(stocks, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add this data to our Data Frame of articles and compare the sentiment and stock price for the last 100 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = stocks[\"Time Series (Daily)\"]\n",
    "\n",
    "i = 0;\n",
    "for k,v in prices.items():\n",
    "    \n",
    "    articles_json[i].update({\"price\": v['4. close']})\n",
    "    i+=1;\n",
    "    \n",
    "df2 = pd.DataFrame.from_dict(json_normalize(articles_json), orient='columns')\n",
    "    \n",
    "print(df2.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This could be an interesting dataset, but it would help to visualize the data to identify potential trends and correlation\n",
    "\n",
    "## But that's a whole other lecture...\n",
    "<br/>\n",
    "\n",
    "**To recap this notebook, we used the following data representations:**\n",
    "* CSV\n",
    "* JSON\n",
    "* DataFrame\n",
    "\n",
    "**And the following libraries:**\n",
    "* csv (python)\n",
    "* json (python)\n",
    "* requests (python)\n",
    "* vader (nltk)\n",
    "* pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
